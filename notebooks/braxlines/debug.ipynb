{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training Mutual Information Maximization (MI-Max) RL algorithms in Brax\n",
        "\n",
        "In [Brax Training](https://colab.research.google.com/github/google/brax/blob/main/notebooks/training.ipynb) we tried out [gym](https://gym.openai.com/)-like environments and PPO, SAC, evolutionary search, and trajectory optimization algorithms. We can build various RL algorithms on top of these ultra-fast implementations. This colab runs a family of [variational GCRL](https://arxiv.org/abs/2106.01404) algorithms or MI-maximization (MI-max) algorithms, which include [goal-conditioned RL](http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.51.3077) and [DIAYN](https://arxiv.org/abs/1802.06070) as special cases. Let's try it out!\n",
        "\n",
        "This provides a bare bone implementation based on minimal modifications to the\n",
        "baseline [PPO](https://github.com/google/brax/blob/main/brax/training/ppo.py),\n",
        "enabling training in a few minutes. More features, examples, and benchmarked results will be added."
      ],
      "metadata": {
        "id": "ssCOanHc8JH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/google/brax/blob/main/notebooks/braxlines/mimax.ipynb)"
      ],
      "metadata": {
        "id": "VYe1kc3a4Oxc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "#@title Colab setup and imports\n",
        "#@markdown ## ⚠️ PLEASE NOTE:\n",
        "#@markdown This colab runs best using a TPU runtime.  From the Colab menu, choose Runtime > Change Runtime Type, then select **'TPU'** in the dropdown.\n",
        "\n",
        "from datetime import datetime\n",
        "import functools\n",
        "import math\n",
        "import os\n",
        "import pprint\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from IPython.display import HTML, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install git+https://github.com/frt03/brax.git@features/amorpheus\n",
        "import brax\n",
        "\n",
        "from brax.io import file as io_file\n",
        "from brax.io import html\n",
        "from brax.training.networks import make_transformers\n",
        "from brax.experimental.composer import composer\n",
        "from brax.experimental.composer import register_default_components\n",
        "from brax.experimental.braxlines.common import evaluators\n",
        "from brax.experimental.braxlines.common import logger_utils\n",
        "from brax.experimental.braxlines.training import ppo\n",
        "from brax.experimental.braxlines.vgcrl import evaluators as vgcrl_evaluators\n",
        "from brax.experimental.braxlines.vgcrl import utils as vgcrl_utils\n",
        "register_default_components()\n",
        "\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "tfp = tfp.substrates.jax\n",
        "tfd = tfp.distributions\n",
        "\n",
        "if \"COLAB_TPU_ADDR\" in os.environ:\n",
        "  from jax.tools import colab_tpu\n",
        "  colab_tpu.setup_tpu()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/frt03/brax.git@features/amorpheus\n",
            "  Cloning https://github.com/frt03/brax.git (to revision features/amorpheus) to /tmp/pip-req-build-jj4cti5z\n",
            "  Running command git clone -q https://github.com/frt03/brax.git /tmp/pip-req-build-jj4cti5z\n",
            "  Running command git checkout -b features/amorpheus --track origin/features/amorpheus\n",
            "  Switched to a new branch 'features/amorpheus'\n",
            "  Branch 'features/amorpheus' set up to track remote branch 'features/amorpheus' from 'origin'.\n",
            "  Resolved https://github.com/frt03/brax.git to commit 6f4ac3c8098e8bf6998cf8bf0c9156d457042572\n",
            "Requirement already satisfied: absl-py in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from brax==0.0.5) (0.13.0)\n",
            "Collecting clu\n",
            "  Using cached clu-0.0.6-py3-none-any.whl (77 kB)\n",
            "Requirement already satisfied: dataclasses in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from brax==0.0.5) (0.8)\n",
            "Requirement already satisfied: flax in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from brax==0.0.5) (0.3.4)\n",
            "Requirement already satisfied: gym in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from brax==0.0.5) (0.19.0)\n",
            "Collecting grpcio\n",
            "  Downloading grpcio-1.40.0-cp36-cp36m-manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jax in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from brax==0.0.5) (0.2.17)\n",
            "Requirement already satisfied: jaxlib in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from brax==0.0.5) (0.1.68)\n",
            "Requirement already satisfied: numpy in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from brax==0.0.5) (1.19.5)\n",
            "Requirement already satisfied: optax in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from brax==0.0.5) (0.0.9)\n",
            "Collecting tfp-nightly[jax]<=0.13.0.dev20210422\n",
            "  Using cached tfp_nightly-0.13.0.dev20210422-py2.py3-none-any.whl (5.3 MB)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from tfp-nightly[jax]<=0.13.0.dev20210422->brax==0.0.5) (1.6.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from tfp-nightly[jax]<=0.13.0.dev20210422->brax==0.0.5) (0.5.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from tfp-nightly[jax]<=0.13.0.dev20210422->brax==0.0.5) (1.16.0)\n",
            "Requirement already satisfied: decorator in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from tfp-nightly[jax]<=0.13.0.dev20210422->brax==0.0.5) (5.1.0)\n",
            "Requirement already satisfied: dm-tree in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from tfp-nightly[jax]<=0.13.0.dev20210422->brax==0.0.5) (0.1.6)\n",
            "Collecting ml-collections\n",
            "  Using cached ml_collections-0.1.0-py3-none-any.whl (88 kB)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.6.0-cp36-cp36m-manylinux2010_x86_64.whl (458.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 458.3 MB 46 kB/s \n",
            "\u001b[?25hCollecting tensorflow-datasets\n",
            "  Using cached tensorflow_datasets-4.4.0-py3-none-any.whl (4.0 MB)\n",
            "Requirement already satisfied: packaging in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from clu->brax==0.0.5) (21.0)\n",
            "Requirement already satisfied: matplotlib in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from flax->brax==0.0.5) (3.3.4)\n",
            "Requirement already satisfied: msgpack in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from flax->brax==0.0.5) (1.0.2)\n",
            "Requirement already satisfied: opt-einsum in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from jax->brax==0.0.5) (3.3.0)\n",
            "Requirement already satisfied: scipy in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from jaxlib->brax==0.0.5) (1.5.4)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from jaxlib->brax==0.0.5) (2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from matplotlib->flax->brax==0.0.5) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from matplotlib->flax->brax==0.0.5) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from matplotlib->flax->brax==0.0.5) (0.10.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from matplotlib->flax->brax==0.0.5) (8.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from matplotlib->flax->brax==0.0.5) (2.8.2)\n",
            "Collecting contextlib2\n",
            "  Using cached contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting PyYAML\n",
            "  Downloading PyYAML-5.4.1-cp36-cp36m-manylinux1_x86_64.whl (640 kB)\n",
            "\u001b[K     |████████████████████████████████| 640 kB 11.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chex>=0.0.4 in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from optax->brax==0.0.5) (0.0.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from chex>=0.0.4->optax->brax==0.0.5) (0.11.1)\n",
            "Collecting keras~=2.6\n",
            "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 9.1 MB/s \n",
            "\u001b[?25hCollecting wrapt~=1.12.1\n",
            "  Using cached wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from tensorflow->clu->brax==0.0.5) (3.18.0)\n",
            "Collecting h5py~=3.1.0\n",
            "  Downloading h5py-3.1.0-cp36-cp36m-manylinux1_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 11.3 MB/s \n",
            "\u001b[?25hCollecting google-pasta~=0.2\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting six>=1.10.0\n",
            "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting tensorboard~=2.6\n",
            "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 9.8 MB/s \n",
            "\u001b[?25hCollecting wheel~=0.35\n",
            "  Downloading wheel-0.37.0-py2.py3-none-any.whl (35 kB)\n",
            "Collecting keras-preprocessing~=1.1.2\n",
            "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Collecting flatbuffers<3.0,>=1.12\n",
            "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting termcolor~=1.1.0\n",
            "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
            "Collecting gast>=0.3.2\n",
            "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting tensorflow-estimator~=2.6\n",
            "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 11.7 MB/s \n",
            "\u001b[?25hCollecting astunparse~=1.6.3\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting clang~=5.0\n",
            "  Downloading clang-5.0.tar.gz (30 kB)\n",
            "Collecting cached-property\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from tensorboard~=2.6->tensorflow->clu->brax==0.0.5) (58.0.0)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
            "\u001b[K     |████████████████████████████████| 288 kB 10.8 MB/s \n",
            "\u001b[?25hCollecting google-auth<2,>=1.6.3\n",
            "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
            "\u001b[K     |████████████████████████████████| 152 kB 9.6 MB/s \n",
            "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 9.1 MB/s \n",
            "\u001b[?25hCollecting requests<3,>=2.21.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
            "  Downloading cachetools-4.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[K     |████████████████████████████████| 155 kB 10.1 MB/s \n",
            "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: importlib-metadata in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->clu->brax==0.0.5) (4.8.1)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting charset-normalizer~=2.0.0\n",
            "  Downloading charset_normalizer-2.0.6-py3-none-any.whl (37 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 10.2 MB/s \n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2021.5.30-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 9.3 MB/s \n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 11.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow->clu->brax==0.0.5) (3.5.0)\n",
            "Collecting promise\n",
            "  Using cached promise-2.3-py3-none-any.whl\n",
            "Collecting future\n",
            "  Using cached future-0.18.2-py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=18.1.0 in /home/linuxpotter/.virtualenvs/jax/lib/python3.6/site-packages (from tensorflow-datasets->clu->brax==0.0.5) (21.2.0)\n",
            "Collecting dill\n",
            "  Using cached dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
            "Collecting importlib-resources\n",
            "  Using cached importlib_resources-5.2.2-py3-none-any.whl (27 kB)\n",
            "Collecting tensorflow-metadata\n",
            "  Using cached tensorflow_metadata-1.2.0-py3-none-any.whl (48 kB)\n",
            "Collecting tqdm\n",
            "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting absl-py\n",
            "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
            "\u001b[K     |████████████████████████████████| 129 kB 10.5 MB/s \n",
            "\u001b[?25hCollecting googleapis-common-protos<2,>=1.52.0\n",
            "  Using cached googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
            "Using legacy 'setup.py install' for brax, since package 'wheel' is not installed.\n",
            "Using legacy 'setup.py install' for clang, since package 'wheel' is not installed.\n",
            "Installing collected packages: urllib3, six, pyasn1, idna, charset-normalizer, certifi, typing-extensions, rsa, requests, pyasn1-modules, oauthlib, flatbuffers, cachetools, absl-py, requests-oauthlib, google-auth, wheel, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, googleapis-common-protos, google-auth-oauthlib, cached-property, wrapt, tqdm, termcolor, tensorflow-metadata, tensorflow-estimator, tensorboard, PyYAML, promise, keras-preprocessing, keras, importlib-resources, h5py, google-pasta, gast, future, dill, contextlib2, clang, astunparse, tfp-nightly, tensorflow-datasets, tensorflow, ml-collections, clu, brax\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 0.13.0\n",
            "    Uninstalling absl-py-0.13.0:\n",
            "      Successfully uninstalled absl-py-0.13.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.2\n",
            "    Uninstalling gast-0.5.2:\n",
            "      Successfully uninstalled gast-0.5.2\n",
            "    Running setup.py install for clang ... \u001b[?25ldone\n",
            "\u001b[?25h    Running setup.py install for brax ... \u001b[?25ldone\n",
            "\u001b[?25hSuccessfully installed PyYAML-5.4.1 absl-py-0.12.0 astunparse-1.6.3 brax-0.0.5 cached-property-1.5.2 cachetools-4.2.2 certifi-2021.5.30 charset-normalizer-2.0.6 clang-5.0 clu-0.0.6 contextlib2-21.6.0 dill-0.3.4 flatbuffers-1.12 future-0.18.2 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 googleapis-common-protos-1.53.0 grpcio-1.40.0 h5py-3.1.0 idna-3.2 importlib-resources-5.2.2 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.4 ml-collections-0.1.0 oauthlib-3.1.1 promise-2.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.26.0 requests-oauthlib-1.3.0 rsa-4.7.2 six-1.15.0 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.0 tensorflow-datasets-4.4.0 tensorflow-estimator-2.6.0 tensorflow-metadata-1.2.0 termcolor-1.1.0 tfp-nightly-0.13.0.dev20210422 tqdm-4.62.3 typing-extensions-3.7.4.3 urllib3-1.26.6 werkzeug-2.0.1 wheel-0.37.0 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'brax.experimental'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5d2d300568a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbrax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mio_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbrax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbrax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetworks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbrax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomposer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomposer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbrax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomposer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregister_default_components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.virtualenvs/jax/lib/python3.6/site-packages/brax/training/networks.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbrax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectral_norm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSNDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbrax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbraxlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformerEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'brax.experimental'"
          ]
        }
      ],
      "metadata": {
        "id": "rlVNS8JstMRr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title Define task and experiment parameters\n",
        "\n",
        "#@markdown **Task Parameters**\n",
        "#@markdown \n",
        "#@markdown As in [DIAYN](https://arxiv.org/abs/1802.06070)\n",
        "#@markdown and [VGCRL](https://arxiv.org/abs/2106.01404),\n",
        "#@markdown we assume some task knowledge about interesting dimensions\n",
        "#@markdown of the environment `obs_indices` and their range `obs_scale`.\n",
        "#@markdown This is also used for evaluation and visualization.\n",
        "#@markdown\n",
        "#@markdown When the **task parameters** are the same, the metrics computed by\n",
        "#@markdown [vgcrl/evaluators.py](https://github.com/google/brax/blob/main/brax/experimental/braxlines/vgcrl/evaluators.py)\n",
        "#@markdown are directly comparable across experiment runs with different\n",
        "#@markdown **experiment parameters**. \n",
        "env_name = 'ant'  # @param ['ant', 'humanoid', 'halfcheetah', 'uni_ant', 'bi_ant']\n",
        "obs_indices = 'vel'  # @param ['vel', 'delta_pos', 'delta_vel']\n",
        "obs_scale = 10.0 #@param{'type': 'number'}\n",
        "obs_indices_str = obs_indices\n",
        "obs_indices = dict(\n",
        "    vel=dict(\n",
        "      ant = (13,14),\n",
        "      humanoid = (22, 23),\n",
        "      halfcheetah = (11,),\n",
        "      uni_ant = (('body_vel:torso_ant1', 0),('body_vel:torso_ant1', 1)),\n",
        "      bi_ant = (('body_vel:torso_ant1', 0),('body_vel:torso_ant2', 0)),\n",
        "    ),\n",
        "    delta_pos=dict(\n",
        "      bi_ant = (('delta_pos', 0),('delta_pos', 1)),\n",
        "    ),\n",
        "    delta_vel=dict(\n",
        "      bi_ant = (('delta_vel', 0),('delta_vel', 1)),\n",
        "    ),\n",
        ")[obs_indices][env_name]\n",
        "\n",
        "#@markdown **Experiment Parameters**\n",
        "#@markdown See [vgcrl/utils.py](https://github.com/google/brax/blob/main/brax/experimental/braxlines/vgcrl/utils.py)\n",
        "evaluate_mi = False # @param{'type': 'boolean'}\n",
        "evaluate_lgr = False # @param{'type': 'boolean'}\n",
        "algo_name = 'diayn'  # @param ['gcrl', 'cdiayn', 'diayn', 'diayn_full', 'fixed_gcrl']\n",
        "env_reward_multiplier =   0# @param{'type': 'number'}\n",
        "obs_norm_reward_multiplier =   0# @param{'type': 'number'}\n",
        "normalize_obs_for_disc = False  # @param {'type': 'boolean'}\n",
        "normalize_obs_for_rl = True # @param {'type': 'boolean'}\n",
        "seed =   0# @param {type: 'integer'}\n",
        "diayn_num_skills = 8  # @param {type: 'integer'}\n",
        "spectral_norm = True  # @param {'type': 'boolean'}\n",
        "output_path = '' # @param {'type': 'string'}\n",
        "task_name = \"\" # @param {'type': 'string'}\n",
        "exp_name = '' # @param {'type': 'string'}\n",
        "if output_path:\n",
        "  output_path = output_path.format(\n",
        "    date=datetime.now().strftime('%Y%m%d'))\n",
        "  task_name = task_name or f'{env_name}_{obs_indices_str}_{obs_scale}'\n",
        "  exp_name = exp_name or algo_name \n",
        "  output_path = f'{output_path}/{task_name}/{exp_name}'\n",
        "print(f'output_path={output_path}')"
      ],
      "outputs": [],
      "metadata": {
        "id": "gh4QsRPnX770"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# @title Initialize Brax environment\n",
        "visualize = False # @param{'type': 'boolean'}\n",
        "\n",
        "# Create baseline environment to get observation specs\n",
        "base_env_fn = composer.create_fn(env_name=env_name)\n",
        "base_env = base_env_fn()\n",
        "\n",
        "# Create discriminator-parameterized environment\n",
        "disc = vgcrl_utils.create_disc_fn(algo_name=algo_name,\n",
        "                   observation_size=base_env.observation_size,\n",
        "                   obs_indices=obs_indices,\n",
        "                   scale=obs_scale,\n",
        "                   diayn_num_skills = diayn_num_skills,\n",
        "                   spectral_norm=spectral_norm,\n",
        "                   env=base_env,\n",
        "                   normalize_obs=normalize_obs_for_disc)()\n",
        "extra_params = disc.init_model(rng=jax.random.PRNGKey(seed=seed))\n",
        "env_fn = vgcrl_utils.create_fn(env_name=env_name, wrapper_params=dict(\n",
        "    disc=disc, env_reward_multiplier=env_reward_multiplier,\n",
        "    obs_norm_reward_multiplier=obs_norm_reward_multiplier, \n",
        "    ))\n",
        "eval_env_fn = functools.partial(env_fn, auto_reset=False)\n",
        "\n",
        "# make inference functions and goals for LGR metric\n",
        "core_env = env_fn()\n",
        "params, inference_fn = ppo.make_params_and_inference_fn(\n",
        "      core_env.observation_size, core_env.action_size,\n",
        "      normalize_observations=normalize_obs_for_rl,\n",
        "      extra_params=extra_params,\n",
        "      make_models_fn=make_transformers)\n",
        "inference_fn = jax.jit(inference_fn)\n",
        "goals = tfd.Uniform(low=-disc.obs_scale, high=disc.obs_scale).sample(\n",
        "    seed=jax.random.PRNGKey(0), sample_shape=(10,))\n",
        "\n",
        "\n",
        "# Visualize\n",
        "if visualize:\n",
        "  env = env_fn()\n",
        "  jit_env_reset = jax.jit(env.reset)\n",
        "  state = jit_env_reset(rng=jax.random.PRNGKey(seed=seed))\n",
        "  clear_output()  # clear out jax.lax warning before rendering\n",
        "  HTML(html.render(env.sys, [state.qp]))"
      ],
      "outputs": [],
      "metadata": {
        "id": "NaJDZqhCLovU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title Training\n",
        "num_timesteps_multiplier =   6# @param {type: 'number'}\n",
        "ncols = 5 # @param{type: 'integer'}\n",
        "\n",
        "tab = logger_utils.Tabulator(output_path=f'{output_path}/training_curves.csv', append=False)\n",
        "\n",
        "# We determined some reasonable hyperparameters offline and share them here.\n",
        "n = num_timesteps_multiplier\n",
        "if env_name == 'humanoid':\n",
        "  train_fn = functools.partial(\n",
        "    ppo.train,\n",
        "    num_timesteps=int(50_000_000 * n),\n",
        "    log_frequency=20,\n",
        "    reward_scaling=0.1,\n",
        "    episode_length=1000,\n",
        "    normalize_observations=normalize_obs_for_rl,\n",
        "    action_repeat=1,\n",
        "    unroll_length=10,\n",
        "    num_minibatches=16,\n",
        "    num_update_epochs=8,\n",
        "    discounting=0.97,\n",
        "    learning_rate=1e-4,\n",
        "    entropy_cost=1e-3,\n",
        "    num_envs=2048,\n",
        "    batch_size=1024,\n",
        "    make_models_fn=make_transformers,\n",
        ")\n",
        "else:\n",
        "  train_fn = functools.partial(\n",
        "    ppo.train,\n",
        "    num_timesteps=int(50_000_000 * n),\n",
        "    log_frequency=20,\n",
        "    reward_scaling=10,\n",
        "    episode_length=1000,\n",
        "    normalize_observations=normalize_obs_for_rl,\n",
        "    action_repeat=1,\n",
        "    unroll_length=5,\n",
        "    num_minibatches=32,\n",
        "    num_update_epochs=4,\n",
        "    discounting=0.95,\n",
        "    learning_rate=3e-4,\n",
        "    entropy_cost=1e-2,\n",
        "    num_envs=2048,\n",
        "    batch_size=1024,\n",
        "    make_models_fn=make_transformers\n",
        ")\n",
        "\n",
        "times = [datetime.now()]\n",
        "plotdata = {}\n",
        "plotkeys = ['eval/episode_reward', 'losses/disc_loss', 'metrics/lgr',\n",
        "            'metrics/entropy_all_', 'metrics/entropy_z_', 'metrics/mi_']\n",
        "\n",
        "def plot(output_path:str =None, output_name:str = 'training_curves'):\n",
        "  matched_keys = [key for key in sorted(plotdata.keys()) if any(plotkey in\n",
        "                                                                key for plotkey in plotkeys)]\n",
        "  num_figs = len(matched_keys)\n",
        "  nrows = int(math.ceil(num_figs/ncols)) \n",
        "  fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=(3.5 * ncols, 3 * nrows))\n",
        "  for i, key in enumerate(matched_keys):\n",
        "    col, row = i % ncols, int(i/ncols)\n",
        "    ax = axs\n",
        "    if nrows > 1:\n",
        "      ax = ax[row]\n",
        "    if ncols > 1:\n",
        "      ax = ax[col]\n",
        "    ax.plot(plotdata[key]['x'], plotdata[key]['y'])\n",
        "    ax.set(xlabel='# environment steps', ylabel=key)\n",
        "    ax.set_xlim([0, train_fn.keywords['num_timesteps']])\n",
        "  fig.tight_layout()\n",
        "  if output_path:\n",
        "    with io_file.File(f'{output_path}/{output_name}.png', 'wb') as f:\n",
        "      plt.savefig(f)\n",
        "\n",
        "def progress(num_steps, metrics, params):\n",
        "  if evaluate_mi:\n",
        "    mi_metrics = vgcrl_evaluators.estimate_empowerment_metric(\n",
        "      env_fn=env_fn, disc=disc, inference_fn=inference_fn, params=params,\n",
        "      # custom_obs_indices = list(range(core_env.observation_size))[:30],\n",
        "      # custom_obs_scale = obs_scale,\n",
        "    )\n",
        "    metrics.update(mi_metrics)\n",
        "  \n",
        "  if evaluate_lgr:\n",
        "    lgr_metrics = vgcrl_evaluators.estimate_latent_goal_reaching_metric( \n",
        "      params=params, env_fn=env_fn, disc=disc, inference_fn=inference_fn,\n",
        "      goals=goals)\n",
        "    metrics.update(lgr_metrics)\n",
        "  \n",
        "  times.append(datetime.now())\n",
        "  for key, v in metrics.items():\n",
        "    plotdata[key] = plotdata.get(key, dict(x=[], y=[]))\n",
        "    plotdata[key]['x'] += [num_steps]\n",
        "    plotdata[key]['y'] += [v]\n",
        "\n",
        "  # the first step does not include losses\n",
        "  if num_steps > 0:\n",
        "    tab.add(num_steps=num_steps, **metrics)\n",
        "    tab.dump()\n",
        "  clear_output(wait=True)\n",
        "  plot()\n",
        "  plt.show()\n",
        "\n",
        "extra_loss_fns = dict(disc_loss=disc.disc_loss_fn) if extra_params else None\n",
        "_, params, _ = train_fn(\n",
        "    environment_fn=env_fn, progress_fn=progress, extra_params=extra_params,\n",
        "    extra_loss_fns=extra_loss_fns,\n",
        ")\n",
        "clear_output(wait=True)\n",
        "plot(output_path=output_path)\n",
        "\n",
        "print(f'time to jit: {times[1] - times[0]}')\n",
        "print(f'time to train: {times[-1] - times[1]}')"
      ],
      "outputs": [],
      "metadata": {
        "id": "4vgMSWODfyMC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title Visualizing skills of the learned inference function in 2D plot\n",
        "num_z = 5  # @param {type: 'integer'}\n",
        "num_samples_per_z = 5  # @param {type: 'integer'}\n",
        "time_subsampling = 10  # @param {type: 'integer'}\n",
        "time_last_n = 500 # @param {type: 'integer'}\n",
        "eval_seed = 0  # @param {type: 'integer'}\n",
        "\n",
        "vgcrl_evaluators.visualize_skills(\n",
        "    env_fn=eval_env_fn,\n",
        "    disc=disc,\n",
        "    inference_fn=inference_fn,\n",
        "    params=params,\n",
        "    output_path=output_path,\n",
        "    verbose=True,\n",
        "    num_z=num_z,\n",
        "    num_samples_per_z=num_samples_per_z,\n",
        "    time_subsampling=time_subsampling,\n",
        "    time_last_n=time_last_n,\n",
        "    save_video=True,\n",
        "    seed=eval_seed)\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "id": "p5eWOxg7RmQQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# @title Estimate [Latent Goal Reaching metric](https://arxiv.org/abs/2106.01404)\n",
        "num_samples_per_z =   10# @param {type: 'integer'}\n",
        "time_subsampling = 1  # @param {type: 'integer'}\n",
        "time_last_n = 500 # @param {type: 'integer'}\n",
        "eval_seed = 0  # @param {type: 'integer'}\n",
        "\n",
        "\n",
        "metrics = vgcrl_evaluators.estimate_latent_goal_reaching_metric( \n",
        "    params=params,\n",
        "    env_fn = eval_env_fn,\n",
        "    disc=disc,\n",
        "    inference_fn=inference_fn,\n",
        "    goals=goals,\n",
        "    num_samples_per_z=num_samples_per_z,\n",
        "    time_subsampling=time_subsampling,\n",
        "    time_last_n=time_last_n,\n",
        "    seed=eval_seed,\n",
        ")\n",
        "pprint.pprint(metrics)"
      ],
      "outputs": [],
      "metadata": {
        "id": "VpAxzRnRu_ej"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title Estimate empowerment metrics using 1D/2D binning\n",
        "num_z =   10# @param {type: 'integer'}\n",
        "num_samples_per_z =   10# @param {type: 'integer'}\n",
        "time_subsampling = 1  # @param {type: 'integer'}\n",
        "time_last_n = 500 # @param {type: 'integer'}\n",
        "eval_seed = 0  # @param {type: 'integer'\n",
        "num_1d_bins = 1000  # @param {type: 'integer'}\n",
        "num_2d_bins =   30# @param {type: 'integer'}\n",
        "\n",
        "metrics = vgcrl_evaluators.estimate_empowerment_metric(\n",
        "    env_fn=eval_env_fn,\n",
        "    disc=disc,\n",
        "    inference_fn=inference_fn,\n",
        "    params=params,\n",
        "    num_z=num_z,\n",
        "    num_samples_per_z=num_samples_per_z,\n",
        "    time_subsampling=time_subsampling,\n",
        "    time_last_n=time_last_n,\n",
        "    num_1d_bins = num_1d_bins,\n",
        "    num_2d_bins = num_2d_bins,\n",
        "    verbose = True,\n",
        "    seed=eval_seed)\n",
        "pprint.pprint(metrics)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Uf5Jvf11NWUm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "#@title Visualizing a trajectory of the learned inference function\n",
        "#@markdown If `z_value` is `None`, sample `z`, else fix `z` to `z_value`.\n",
        "z_value =   0# @param {'type': 'raw'}\n",
        "eval_seed = 0  # @param {'type': 'integer'}\n",
        "\n",
        "z = {\n",
        "    'fixed_gcrl': jnp.ones(disc.z_size) * z_value,\n",
        "    'gcrl': jnp.ones(disc.z_size) * z_value,\n",
        "    'cdiayn': jnp.ones(disc.z_size) * z_value,\n",
        "    'diayn': jax.nn.one_hot(jnp.array(int(z_value)), disc.z_size),\n",
        "    'diayn_full': jax.nn.one_hot(jnp.array(int(z_value)), disc.z_size),\n",
        "}[algo_name] if z_value is not None else None\n",
        "\n",
        "env, states = evaluators.visualize_env(\n",
        "    env_fn=eval_env_fn,\n",
        "    inference_fn=inference_fn,\n",
        "    params=params,\n",
        "    batch_size=0,\n",
        "    seed = eval_seed,\n",
        "    reset_args = (z,),\n",
        "    step_args = (params['normalizer'], params['extra']),\n",
        "    output_path=output_path,\n",
        "    output_name=f'video_z_{z_value}',\n",
        ")\n",
        "HTML(html.render(env.sys, [state.qp for state in states]))"
      ],
      "outputs": [],
      "metadata": {
        "id": "RNMLEyaTspEM"
      }
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/deepmind/public/tools/ml_python:ml_notebook",
        "kind": "private"
      },
      "name": "mimax.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1ZaAO4BS2tJ_03CIXdBCFibZR2yLl6dtv",
          "timestamp": 1631716086810
        }
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.6.9 64-bit ('jax': virtualenv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "50e234aee50bb874acf34bb465606f3fb2aefe54fd1db2a536f430eabbecf714"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}